---
phase: 03-container-creation
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - apps/dashboard/src/lib/db.ts
  - apps/dashboard/src/workers/container-creation.ts
autonomous: true

must_haves:
  truths:
    - "Worker process starts via tsx and connects to Redis with maxRetriesPerRequest: null"
    - "Worker picks up jobs from container-creation queue and executes the 5-phase pipeline"
    - "Each pipeline phase publishes progress events to Redis Pub/Sub channel container:<id>:progress"
    - "Each pipeline phase persists ContainerEvent records in the database"
    - "Container lifecycle transitions: creating → ready on success, creating → error on failure"
    - "Worker handles graceful shutdown on SIGTERM/SIGINT"
  artifacts:
    - path: "apps/dashboard/src/workers/container-creation.ts"
      provides: "BullMQ Worker process with 5-phase container creation pipeline"
      contains: "new Worker"
      min_lines: 150
  key_links:
    - from: "apps/dashboard/src/workers/container-creation.ts"
      to: "apps/dashboard/src/lib/proxmox/containers.ts"
      via: "Calls createContainer, startContainer via Proxmox API"
      pattern: "createContainer|startContainer"
    - from: "apps/dashboard/src/workers/container-creation.ts"
      to: "apps/dashboard/src/lib/ssh.ts"
      via: "Uses SSHSession for post-creation deployment"
      pattern: "SSHSession|connectWithRetry"
    - from: "apps/dashboard/src/workers/container-creation.ts"
      to: "apps/dashboard/src/lib/queue/container-creation.ts"
      via: "Imports ContainerJobData type and getProgressChannel"
      pattern: "ContainerJobData|getProgressChannel"
    - from: "apps/dashboard/src/workers/container-creation.ts"
      to: "apps/dashboard/src/lib/db.ts"
      via: "Updates Container lifecycle and creates ContainerEvent records"
      pattern: "prisma\\.container\\.(update|findUnique)|prisma\\.containerEvent\\.create"
---

<objective>
Build the BullMQ worker process that executes the 5-phase container creation pipeline: Create → Start → Deploy (SSH) → Sync (SSH) → Finalize. The worker runs as a standalone process, publishes real-time progress via Redis Pub/Sub, and persists events in the database.

Purpose: This is the backend engine that turns a wizard submission into a running, configured container. It bridges the Proxmox API, SSH deployment, and progress tracking systems.

Output: A worker file at `src/workers/container-creation.ts` runnable via `tsx --watch`.
</objective>

<execution_context>
@/home/coder/.config/Claude/get-shit-done/workflows/execute-plan.md
@/home/coder/.config/Claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-container-creation/03-RESEARCH.md
@.planning/phases/03-container-creation/03-01-SUMMARY.md

@apps/dashboard/src/lib/proxmox/containers.ts
@apps/dashboard/src/lib/proxmox/tasks.ts
@apps/dashboard/src/lib/proxmox/index.ts
@apps/dashboard/src/lib/ssh.ts
@apps/dashboard/src/lib/queue/container-creation.ts
@apps/dashboard/src/lib/redis.ts
@apps/dashboard/src/lib/db.ts
@apps/dashboard/prisma/schema.prisma
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add DatabaseService container methods and export prisma instance</name>
  <files>
    apps/dashboard/src/lib/db.ts
  </files>
  <action>
Extend `src/lib/db.ts` with two things:

**1. Export the prisma instance** for direct access in complex operations (the worker needs raw Prisma for transactions):

Add at the bottom of the file, after the DatabaseService class:

```ts
export { prismaInstance as prisma };
```

**2. Add Container + ContainerEvent methods to DatabaseService:**

```ts
// Inside DatabaseService class, after existing Node methods:

// ============================================================================
// Container Operations
// ============================================================================

static async createContainer(data: {
  vmid: number;
  rootPassword: string; // Already encrypted
  nodeId: string;
  templateId?: string;
}): Promise<Container> {
  return this.prisma.container.create({ data });
}

static async getContainerById(id: string): Promise<Container | null> {
  return this.prisma.container.findUnique({
    where: { id },
    include: { node: true, template: true },
  });
}

static async updateContainerLifecycle(
  id: string,
  lifecycle: ContainerLifecycle,
): Promise<Container> {
  return this.prisma.container.update({
    where: { id },
    data: { lifecycle },
  });
}

// ============================================================================
// ContainerEvent Operations
// ============================================================================

static async createContainerEvent(data: {
  containerId: string;
  type: EventType;
  message: string;
  metadata?: string; // JSON string
}): Promise<ContainerEvent> {
  return this.prisma.containerEvent.create({ data });
}

static async getContainerEvents(containerId: string): Promise<ContainerEvent[]> {
  return this.prisma.containerEvent.findMany({
    where: { containerId },
    orderBy: { createdAt: "asc" },
  });
}
```

Import the necessary types at the top (add to existing import):

```ts
import type {
  ProxmoxNode,
  Container,
  ContainerEvent,
  ContainerLifecycle,
  EventType,
} from "@/generated/prisma/client";
```

Also import the `ContainerLifecycle` and `EventType` enums as values (not just types) since they're needed at runtime — use:

```ts
import { ContainerLifecycle, EventType } from "@/generated/prisma/client";
```

Re-export the enums from db.ts so the worker can import them:

```ts
export { ContainerLifecycle, EventType };
```

  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - `grep "prisma" apps/dashboard/src/lib/db.ts | grep "export"` shows the prisma export
    - DatabaseService has createContainer, getContainerById, updateContainerLifecycle, createContainerEvent, getContainerEvents methods
  </verify>
  <done>
    - prisma instance exported for direct use in complex transactions
    - DatabaseService has Container CRUD and ContainerEvent methods
    - ContainerLifecycle and EventType enums re-exported for worker use
  </done>
</task>

<task type="auto">
  <name>Task 2: Container creation worker with 5-phase pipeline</name>
  <files>
    apps/dashboard/src/workers/container-creation.ts
  </files>
  <action>
Create `src/workers/container-creation.ts` — the standalone BullMQ worker process.

**File structure:**

1. **Imports:**

   ```ts
   import { Worker, Job } from "bullmq";
   import Redis from "ioredis";
   import {
     type ContainerJobData,
     type ContainerJobResult,
     type ContainerProgressEvent,
     getProgressChannel,
   } from "../lib/queue/container-creation";
   import {
     DatabaseService,
     ContainerLifecycle,
     EventType,
     prisma,
   } from "../lib/db";
   import { createProxmoxClientFromNode } from "../lib/proxmox";
   import { createContainer, startContainer } from "../lib/proxmox/containers";
   import { waitForTask } from "../lib/proxmox/tasks";
   import { connectWithRetry, type SSHSession } from "../lib/ssh";
   import { decrypt } from "../lib/encryption";
   ```

2. **Redis connections:** Create TWO separate Redis connections:

   ```ts
   const workerConnection = new Redis(process.env.REDIS_URL!, {
     maxRetriesPerRequest: null, // REQUIRED for BullMQ Worker
   });
   const publisher = new Redis(process.env.REDIS_URL!);
   ```

3. **Progress helper:**

   ```ts
   async function publishProgress(
     containerId: string,
     event: Omit<ContainerProgressEvent, "timestamp">,
   ): Promise<void> {
     const fullEvent: ContainerProgressEvent = {
       ...event,
       timestamp: new Date().toISOString(),
     };
     // Publish to Redis for SSE subscribers
     await publisher.publish(
       getProgressChannel(containerId),
       JSON.stringify(fullEvent),
     );
     // Persist to database for late subscribers / audit trail
     await DatabaseService.createContainerEvent({
       containerId,
       type:
         event.type === "complete"
           ? EventType.created
           : event.type === "error"
             ? EventType.error
             : event.type === "step" && event.step === "starting"
               ? EventType.started
               : EventType.script_completed,
       message: event.message,
       metadata: JSON.stringify({ step: event.step, percent: event.percent }),
     });
   }
   ```

   Note: Map ContainerProgressEvent types to EventType enum values. Not all progress events need DB persistence — only `step` and terminal events. For `log` type events, skip DB persistence (too many rows) but still publish to Redis.

   Revise: Only persist to DB for `step`, `complete`, and `error` events. For `log` events, only publish to Redis (fire-and-forget for real-time display).

4. **5-Phase Pipeline — `processContainerCreation(job: Job<ContainerJobData, ContainerJobResult>)`:**

   **Phase 1: Create Container (0-20%)**
   - Fetch the ProxmoxNode from DB using `job.data.nodeId`
   - Create ProxmoxClient from node (`createProxmoxClientFromNode`)
   - Publish step: `{ type: "step", step: "creating", percent: 5, message: "Creating LXC container..." }`
   - Call `createContainer(client, node.name, { ... })` mapping job.data.config to `ProxmoxContainerCreateConfig`
   - The create call returns a UPID — poll with `waitForTask(client, node.name, upid, { interval: 2000, timeout: 120000 })`
   - Publish step: `{ type: "step", step: "creating", percent: 20, message: "Container created successfully" }`

   **Phase 2: Start Container (20-35%)**
   - Publish step: `{ type: "step", step: "starting", percent: 25, message: "Starting container..." }`
   - Call `startContainer(client, node.name, job.data.config.vmid)`
   - Poll UPID with `waitForTask`
   - Publish step: `{ type: "step", step: "starting", percent: 35, message: "Container started" }`

   **Phase 3: Deploy config-manager via SSH (35-60%)**
   - Publish step: `{ type: "step", step: "deploying", percent: 40, message: "Connecting to container via SSH..." }`
   - Determine container IP. For DHCP: query the Proxmox API for the container's network interfaces using `client.get(\`/nodes/${node.name}/lxc/${vmid}/interfaces\`)`(may need to add this endpoint). Alternatively, if ipConfig is static (e.g.,`ip=10.0.0.50/24`), parse the IP from the config. For now, implement the static IP extraction and add a TODO for DHCP discovery.
   - Connect via SSH using `connectWithRetry({ host: containerIp, username: "root", password: job.data.config.rootPassword })` — this retries since SSH takes seconds to become available after container boot.
   - Fetch template with scripts, files, packages from DB:
     ```ts
     const template = await prisma.template.findUnique({
       where: { id: job.data.templateId },
       include: {
         scripts: { where: { enabled: true }, orderBy: { order: "asc" } },
         files: true,
         packages: true,
       },
     });
     ```
   - Upload each template file via SSH: `ssh.uploadFile(file.content, file.targetPath + "/" + file.name, 0o644)`
   - Publish log events for each file uploaded
   - Publish step: `{ type: "step", step: "deploying", percent: 60, message: "Template files deployed" }`

   **Phase 4: Run initial sync — execute scripts (60-90%)**
   - Publish step: `{ type: "step", step: "syncing", percent: 65, message: "Running setup scripts..." }`
   - For each enabled script (sorted by order):
     - Upload script content to `/tmp/{script.name}` with mode `0o755`
     - Execute via `ssh.execStreaming("bash /tmp/{script.name}", (line, isStderr) => { publishProgress(containerId, { type: "log", message: line }) })`
     - Check exit code — if non-zero, throw error with script name
     - Publish percentage incrementally across scripts (e.g., distribute 60-90% evenly)
   - Publish step: `{ type: "step", step: "syncing", percent: 90, message: "Setup scripts completed" }`

   **Phase 5: Finalize (90-100%)**
   - Publish step: `{ type: "step", step: "finalizing", percent: 95, message: "Finalizing container..." }`
   - Update container lifecycle to `ready`: `DatabaseService.updateContainerLifecycle(containerId, ContainerLifecycle.ready)`
   - Close SSH session
   - Publish: `{ type: "complete", percent: 100, message: "Container ready!" }`

   **Error handling:** Wrap entire pipeline in try/catch:
   - On error: update lifecycle to `error`, publish `{ type: "error", message: error.message }`, close SSH if open
   - Always close SSH in finally block
   - Return `{ success: false, containerId, vmid, error: error.message }` on failure
   - Return `{ success: true, containerId, vmid }` on success

5. **Worker instantiation:**

   ```ts
   const worker = new Worker<ContainerJobData, ContainerJobResult>(
     "container-creation",
     processContainerCreation,
     {
       connection: workerConnection,
       concurrency: 2, // Process up to 2 containers simultaneously
     },
   );

   worker.on("completed", (job, result) => {
     console.log(`Job ${job.id} completed:`, result);
   });

   worker.on("failed", (job, err) => {
     console.error(`Job ${job?.id} failed:`, err.message);
   });
   ```

6. **Graceful shutdown:**

   ```ts
   async function shutdown() {
     console.log("Shutting down worker...");
     await worker.close();
     await publisher.quit();
     await workerConnection.quit();
     process.exit(0);
   }

   process.on("SIGTERM", shutdown);
   process.on("SIGINT", shutdown);
   ```

7. **Startup log:**
   ```ts
   console.log("Container creation worker started. Waiting for jobs...");
   ```

**IP extraction helper** (used in Phase 3):

```ts
function extractIpFromConfig(ipConfig: string): string | null {
  // Handle "ip=10.0.0.50/24,gw=10.0.0.1"
  const match = ipConfig.match(/ip=(\d+\.\d+\.\d+\.\d+)/);
  return match ? match[1] : null;
}
```

If IP is "dhcp" or extraction fails, throw an error with clear message: "Cannot determine container IP. DHCP discovery not yet implemented. Use static IP in container config."
</action>
<verify> - `npx tsc --noEmit` passes in apps/dashboard - `apps/dashboard/src/workers/container-creation.ts` exists and is >150 lines - File imports from lib/queue, lib/proxmox, lib/ssh, lib/db correctly - Worker uses `maxRetriesPerRequest: null` for its Redis connection - `grep "new Worker" apps/dashboard/src/workers/container-creation.ts` finds the worker instantiation - `grep "SIGTERM" apps/dashboard/src/workers/container-creation.ts` finds graceful shutdown
</verify>
<done> - Worker process runs as standalone tsx script - 5-phase pipeline: Create → Start → Deploy files (SSH) → Run scripts (SSH) → Finalize - Progress published to Redis Pub/Sub (container:<id>:progress channel) - Step events persisted to ContainerEvent table for late subscriber replay - Log events published to Redis only (no DB persistence for high-frequency logs) - Container lifecycle updated: creating → ready (success) or creating → error (failure) - Graceful shutdown on SIGTERM/SIGINT - Static IP extraction from config; DHCP discovery deferred with clear error
</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` — all types valid, worker compiles
2. Worker file has correct Redis connection (maxRetriesPerRequest: null)
3. All 5 pipeline phases present with progress publishing
4. Error handling catches failures and transitions lifecycle to `error`
5. SSH session is always closed in finally block
6. ContainerEvent records created for step transitions
7. Graceful shutdown handles SIGTERM/SIGINT
</verification>

<success_criteria>

- Worker starts via `pnpm dev:worker` (tsx --watch)
- Worker connects to Redis and waits for jobs
- On job receipt, executes 5-phase pipeline with real-time progress
- Progress events reach Redis Pub/Sub channel
- Container lifecycle transitions correctly in database
- Failed jobs produce error events and update lifecycle to error
- Worker shuts down cleanly on SIGTERM
  </success_criteria>

<output>
After completion, create `.planning/phases/03-container-creation/03-02-SUMMARY.md`
</output>
